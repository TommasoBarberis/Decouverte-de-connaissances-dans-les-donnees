{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tommaso BARBERIS p1708628\n",
    "- Bertrand HUGUENIN-BIZOT p2019360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Clustering de time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez trouver dans ce _notebook_ jupyter nos lignes de codes permettant de faire le clustering sur de données de type __time-series__. Pour faire cela on utilisera deux approche différents qu'on comparera par la suite: <br/>\n",
    "- clustering de type \"hierarchique\"\n",
    "- autre type de clustering, de notre choix\n",
    "\n",
    "Pour les deux méthodes, on s'appuyera sur deux types de distances, la distance __euclidienne__ et la distance dite __Dynamic Time Warping__ (__DTW__). Pour évaluer les deux clustering, on calculera le score de __Rand__.\n",
    "\n",
    "### Dynamic Time Warping\n",
    "Dynamic Time Warping (DTW) est un moyen de comparer deux séquences - généralement temporelles - qui ne se synchronisent pas parfaitement. C'est une méthode pour calculer la correspondance optimale entre deux séquences. DTW est utile dans de nombreux domaines tels que la reconnaissance vocale, l'exploration de données, les marchés financiers, la bio-informatique etc. Il est couramment utilisé dans l'exploration de données pour mesurer la distance entre deux séries chronologiques.\n",
    "\n",
    "\n",
    "### Indice de Rand\n",
    "Il s'agit d'une mesure utilisée en dans le clustering de données qui permet la comparaison de deux partitionnements.\n",
    "\n",
    "#### Définition\n",
    "Donné un ensemble de $n$ éléments $S = {o_1, ..., o_n}$ et deux partitionnements de $S$ à comparer, $X = {X_1, ..., X_r}$ un partitionnement de $S$ en $r$ sous-ensembles, et $Y = {Y_1, .., Y_s}$ un partitionnement de $S$ en $s$ sous-ensembles, on peut définir: <br/>\n",
    "- $a$, le nombre de paires d'éléments en $S$ qui sont dans le même sous-ensemble de $X$ et de $Y$;\n",
    "- $b$, le nombre de paires d'éléments en $S$ qui sont dans sous-ensembles différents de $X$ et de $Y$;\n",
    "- $c$, le nombre de paires d'éléments en $S$ qui sont dans le même sous-ensemble de $X$ mais en sous-ensemble différents de $Y$;\n",
    "- $d$, le nombre de paires d'éléments en $S$ qui sont dans sous-ensembles différents de $X$ mais dans le même sous-ensemble de $Y$.\n",
    "\n",
    "L'indice de Rand est donc calculé ainsi: <br/><br/>\n",
    "<center>$R = \\frac{a + b}{a + b + c + d} = \\frac{a + b}{n \\choose k}$</center>\n",
    "\n",
    "<br/>\n",
    "Pour pouvoir les deux types de distance et de clustering, on utilisera l'index de __Rand ajustée__ (la formule mathématique ne sera pas montré ici), qui permet de corriger le fait de regrouper certains éléments uniquement par chance.\n",
    "\n",
    "<br/><br/>\n",
    "source: [Objective Criteria for the Evaluation of Clustering Methods](https://doi.org/10.2307%2F2284239)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import of libraries\n",
    "\n",
    "from scipy.cluster.hierarchy import complete, fcluster, dendrogram, linkage\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from dtaidistance import clustering, dtw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Plane_TRAIN\", sep=\",\", header=None)\n",
    "\n",
    "group=np.array(list(data.iloc[0:,0]))\n",
    "data = data.iloc[0:,1:]\n",
    "time_series = np.array(data)\n",
    "num_group = len(set(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clustering hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Avec distance euclidienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation graphique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_eucl = linkage(time_series, method='complete', metric='euclidean')\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "\n",
    "dendrogram(linked_eucl,\n",
    "            orientation='top',\n",
    "            labels=list(group),\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True\n",
    "          )\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du score de Rand pour estimer la correspondance entre les clusters créés et les classes initiales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_eucl = list(fcluster(linked_eucl, num_group, criterion='maxclust')) # assignation des séries temporelles aux 7 clusters correspondant aux 7 classes\n",
    "\n",
    "adjusted_rand_score(clust_eucl, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Avec distance DTW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation graphique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = dtw.distance_matrix_fast(time_series, use_mp=True)\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "condensed_dist = squareform(distance)\n",
    "linked_dtw = linkage(condensed_dist)\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "\n",
    "dendrogram(linked_dtw,\n",
    "            orientation='top',\n",
    "            labels=list(group),\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True\n",
    "          )\n",
    "plt.tick_params(axis='x', labelsize=16)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du score de Rand pour estimer la correspondance entre les clusters créés et les classes initiales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_dtw = list(fcluster(linked_dtw, num_group, criterion='maxclust')) # assignation des séries temporelles aux 7 clusters correspondant aux 7 classes\n",
    "\n",
    "adjusted_rand_score(clust_dtw, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En comparant les deux métriques pour le clustering hierarchique, on peut rapidement s'apercevoir que la métrique __DTW__ offre un clustering bien meilleure qu'avec la distance __euclidienne__.\n",
    "On peut le voir graphiquement, les séries témporelles correspondant à une même classe sont quasiment toutes réunies dans le même cluster pour __DTW__ (exception d'une série appartenant à la classe __2__) alors que dans l'autre dendogramme on retrouve des séries disjointes des autres série de même classe (séries des classes __5__, __1__ et __2__). <br/>\n",
    "Par ailleurs, cela se confirme avec le score de l'index de __Rand__, lequel a une valeur de __0.86__ pour le __DTW__ et d'uniquement __0.62__ pour la distance __euclidienne__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clustering avec k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmean_plot(model, label, num_group, time_series, title):\n",
    "    \"\"\"\n",
    "    Fonction qui permet de répresenter les séries temporelles regroupées par cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "\n",
    "    for clust in range(num_group):\n",
    "\n",
    "        plt.subplot(3, 3, clust + 1)    \n",
    "       \n",
    "        for serie in time_series[label == clust+1]:\n",
    "            plt.plot(serie.ravel(), \"k-\", alpha=.2)\n",
    "        \n",
    "        if model != \"null\":\n",
    "            plt.plot(model.cluster_centers_[clust].ravel(), \"r-\")\n",
    "        plt.xlim(0, time_series.shape[1])\n",
    "        plt.ylim(-4, 4)\n",
    "        plt.text(0.55, 0.85,'Cluster %d' % (clust + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "        if clust == 1:\n",
    "            plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation des séries témporelles en fonction de la classe d'origine (permettra l'évaluation du clustering):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_plot(model=\"null\", label=group, num_group=num_group, time_series=time_series, title=\"Classe d'origine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Avec distance euclidienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "model_eucl = TimeSeriesKMeans(n_clusters=num_group, metric=\"euclidean\")\n",
    "label_eucl = model_eucl.fit_predict(time_series) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation graphique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmean_plot(model_eucl, label_eucl, num_group, time_series, \"euclidean k-mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du score de Rand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(label_eucl, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Avec distance DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtw = TimeSeriesKMeans(n_clusters=num_group, metric=\"dtw\")\n",
    "label_dtw = model_dtw.fit_predict(time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representation graphique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmean_plot(model_dtw, label_dtw, num_group, time_series, \"DTW k-mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calcul du score de Rand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_rand_score(label_dtw, group)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
